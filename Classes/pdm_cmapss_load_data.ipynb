{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6 color = green><b> Predicitive Maintenance / 智能性维护实例 </b></font>\n",
    "# Step One: Load Load / 第一步： 读取数据 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries / 工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisite / 准备工作\n",
    "* Download / 下载压缩数据 from https://onedrive.live.com/?cid=7CAD6DA55D313592&id=7CAD6DA55D313592%21159&parId=7CAD6DA55D313592%21158&o=OneUp \n",
    "* Save CMAPSS zipfile to  C:/pdm/zipraw / 把下载的压缩文件存放在 C:/pdm/zipraw    \n",
    "  （ or / 或 d:/pdm/zipraw）\n",
    "* Unzipped data will be stored in raw data folder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Ulitity / 解压\n",
    "* Use zipfile library to unzip / 用 zipfile 工具包解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_files(zip_file_name = None, unzip_to_folder = None, remove_zipped = False):\n",
    "    if not zip_file_name: \n",
    "        current_folder = os.getcwd() # or: os.path.dirname(current_folder)\n",
    "        parent_folder = Path(os.getcwd()).parent.absolute() \n",
    "        zip_file_name = Path(parent_folder ,  \"zipraw/CMAPSS.zip\")\n",
    "    if not unzip_to_folder:\n",
    "        unzip_to_folder = str(parent_folder) +  \"/raw_data\"\n",
    "\n",
    "    if not os.path.exists(unzip_to_folder):\n",
    "        os.makedirs(unzip_to_folder)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_to_folder)\n",
    "\n",
    "    if remove_zipped: \n",
    "        os.remove(zip_file_name)\n",
    "\n",
    "    return [unzip_to_folder + \"/\" + file for file in os.listdir(unzip_to_folder)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System Manipulations / 文件处理\n",
    "* Use regex / 用Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(raw_file_folder = None):\n",
    "    if not raw_file_folder:\n",
    "        raw_file_folder = unzip_to_folder = os.getcwd() +  \"/raw_data\"\n",
    "    return [raw_file_folder + \"/\" + file for file in os.listdir(raw_file_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_regex(raw_file_folder = None, file_name_str = \"test\"):\n",
    "    if not raw_file_folder:\n",
    "        raw_file_folder = unzip_to_folder = os.getcwd() +  \"/raw_data\" \n",
    "    raw_files = list_files(raw_file_folder = raw_file_folder)\n",
    "    regex = re.compile(f\".+{file_name_str}.+gz\")  \n",
    "    raw_data_files = [f for f in raw_files if re.match(regex, f)]\n",
    "    return raw_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to dataframe / 读取到 pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_files(raw_file_folder = None, file_name_str = \"train\", use_pd = True, sep = \" \", columns = None):  \n",
    "    if not columns:\n",
    "        columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "            \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "            ,\"sensor20\",\"sensor21\" ]  \n",
    "\n",
    "    raw_data_files = get_files_regex(raw_file_folder = raw_file_folder, file_name_str =file_name_str) \n",
    "\n",
    "    df_total =  pd.DataFrame() \n",
    "    for f in raw_data_files: \n",
    "        if use_pd:\n",
    "            df_ = pd.read_csv(f, compression='gzip',index_col = False, names = columns, sep=' ')\n",
    "        else: \n",
    "            df_= pd.DataFrame(np.loadtxt(f), columns=columns) \n",
    "        df_[[\"id\", \"cycle\"]] = df_[[\"id\", \"cycle\"]].astype(int)\n",
    "            \n",
    "        flag = re.findall(r\"FD\\d{3}\", str(f))[0]\n",
    "        df_[\"Flag\"] = flag \n",
    "        if df_total.empty:\n",
    "            df_total = df_.copy()\n",
    "        else: \n",
    "            df_total = pd.concat([df_total, df_], axis = 0 ) \n",
    "    \n",
    "    return df_total \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result(raw_file_folder = None, file_name_str = \"RUL_FD\", use_pd = True, sep = \" \", columns = None):\n",
    "    raw_data_files = get_files_regex(raw_file_folder = raw_file_folder, file_name_str =file_name_str)  \n",
    "    if not columns:\n",
    "        columns = [\"rul\"]\n",
    "\n",
    "    df_result =  pd.DataFrame() \n",
    "    for f in raw_data_files:\n",
    "        if use_pd: \n",
    "            df_ = pd.read_csv(f, compression='gzip', index_col = False, names = columns, sep = sep)\n",
    "        else:\n",
    "            df_= pd.DataFrame(np.loadtxt(f), columns = columns) \n",
    "        flag = re.findall(r\"FD\\d{3}\", str(f))[0]\n",
    "        df_[\"Flag\"] = flag \n",
    "        if df_result.empty:\n",
    "            df_result = df_.copy()\n",
    "        else: \n",
    "            df_result = pd.concat([df_result, df_], axis = 0 ) \n",
    "    return df_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum Up: prepare train, test and result file / 主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dfs(raw_file_folder = None, use_pd = True, sep = \" \"):\n",
    "     if not raw_file_folder:\n",
    "          raw_file_folder = unzip_to_folder = os.getcwd() +  \"/raw_data\"\n",
    "\n",
    "     raw_files = list_files(raw_file_folder = raw_file_folder)\n",
    "\n",
    "     columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "          \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "          ,\"sensor20\",\"sensor21\" ] \n",
    "\n",
    "     # Train\n",
    "     df_train = read_data_files(raw_file_folder = raw_file_folder,\n",
    "          file_name_str = \"train\", use_pd = use_pd, sep = \" \", columns = columns)\n",
    "     # Test\n",
    "     df_test = read_data_files(raw_file_folder = raw_file_folder,\n",
    "          file_name_str = \"test\", use_pd = use_pd, sep = \" \", columns = columns)\n",
    "\n",
    "     resul_columns = [\"rul\"]\n",
    "     df_result = read_result(raw_file_folder = raw_file_folder, file_name_str = \"RUL_FD\", \\\n",
    "          use_pd = use_pd, sep =sep, columns = resul_columns)\n",
    " \n",
    "     df_train.iloc[:, [0,1]] = df_train.iloc[:, [0,1]].astype(int)\n",
    "     df_test.iloc[:, [0,1]] = df_test.iloc[:, [0,1]].astype(int) \n",
    "\n",
    "     df_max = df_test.groupby([\"Flag\",\"id\"])[\"cycle\"].max().reset_index()\n",
    "     df_result = df_result.reset_index()\n",
    "     df_result[\"id\"] = df_result.groupby(\"Flag\")[\"index\"].rank(\"first\", ascending = True).astype(int)\n",
    "     df_result.drop(columns = [\"index\"], inplace = True)\n",
    "     \n",
    "     df_result = df_result.merge(df_max, on = [\"Flag\", \"id\"], how = \"inner\")\n",
    "      \n",
    "     df_result[\"rul_failed\"] = df_result[\"rul\"] + df_result[\"cycle\"]\n",
    "\n",
    "     df_test = df_test.merge(df_result[[\"rul_failed\", \"Flag\", \"id\"]], on = [\"Flag\", \"id\"], how = \"inner\")\n",
    "     df_test[\"remaining_rul\"] = df_test[\"rul_failed\"] - df_test[\"cycle\"]\n",
    "\n",
    "     #df_test[[\"rul_failed\", \"remaining_rul\"]] = df_test[[\"rul_failed\", \"remaining_rul\"]].astype(int)\n",
    "     return df_train, df_test, df_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call  prepare_dfs（）  / 调用主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, df_result = prepare_dfs(use_pd=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3361607028a07fbbc80f378608ecaa72f5ffca90043f5aaa255f4292887cf27e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
