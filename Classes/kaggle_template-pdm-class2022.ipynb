{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our Libs ","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas \nimport numpy\nfrom pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:47:12.898635Z","iopub.execute_input":"2022-10-01T23:47:12.899106Z","iopub.status.idle":"2022-10-01T23:47:12.905247Z","shell.execute_reply.started":"2022-10-01T23:47:12.899071Z","shell.execute_reply":"2022-10-01T23:47:12.904063Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# List All files ","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:43:27.187401Z","iopub.execute_input":"2022-10-01T23:43:27.187824Z","iopub.status.idle":"2022-10-01T23:43:27.194062Z","shell.execute_reply.started":"2022-10-01T23:43:27.187791Z","shell.execute_reply":"2022-10-01T23:43:27.192565Z"}}},{"cell_type":"code","source":"def list_data_files(): \n    files = []\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            files.append(os.path.join(dirname, filename))\n    return files\n         \ndef get_files_regex(file_name_str = \"test\"): \n    raw_files = list_data_files()\n    regex = re.compile(f\".+{file_name_str}.+txt\")  \n    raw_data_files = [f for f in raw_files if re.match(regex, f)]\n    return raw_data_files","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:47:50.604440Z","iopub.execute_input":"2022-10-01T23:47:50.605050Z","iopub.status.idle":"2022-10-01T23:47:50.613442Z","shell.execute_reply.started":"2022-10-01T23:47:50.605004Z","shell.execute_reply":"2022-10-01T23:47:50.612095Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Load to dataframe / 读取到 pandas DataFrames ","metadata":{}},{"cell_type":"code","source":"def read_data_files(file_name_str = \"train\", use_pd = True, sep = \" \", columns = None):  \n    if not columns:\n        columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n            \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n            ,\"sensor20\",\"sensor21\" ]  \n\n    raw_data_files = get_files_regex(file_name_str =file_name_str) \n\n    df_total =  pd.DataFrame() \n    for f in raw_data_files: \n        if use_pd:\n            df_ = pd.read_csv(f,  index_col = False, names = columns, sep=' ')\n        else: \n            df_= pd.DataFrame(np.loadtxt(f), columns=columns) \n        df_[[\"id\", \"cycle\"]] = df_[[\"id\", \"cycle\"]].astype(int)\n            \n        flag = re.findall(r\"FD\\d{3}\", str(f))[0]\n        df_[\"Flag\"] = flag \n        if df_total.empty:\n            df_total = df_.copy()\n        else: \n            df_total = pd.concat([df_total, df_], axis = 0 ) \n    \n    return df_total ","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:48:10.317659Z","iopub.execute_input":"2022-10-01T23:48:10.318122Z","iopub.status.idle":"2022-10-01T23:48:10.329241Z","shell.execute_reply.started":"2022-10-01T23:48:10.318086Z","shell.execute_reply":"2022-10-01T23:48:10.327551Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":" def read_result(file_name_str = \"RUL_FD\", use_pd = True, sep = \" \", columns = None):\n    raw_data_files = get_files_regex(file_name_str =file_name_str)  \n    if not columns:\n        columns = [\"rul\"]\n\n    df_result =  pd.DataFrame() \n    for f in raw_data_files:\n        if use_pd: \n            df_ = pd.read_csv(f,  index_col = False, names = columns, sep = sep)\n        else:\n            df_= pd.DataFrame(np.loadtxt(f), columns = columns) \n        flag = re.findall(r\"FD\\d{3}\", str(f))[0]\n        df_[\"Flag\"] = flag \n        if df_result.empty:\n            df_result = df_.copy()\n        else: \n            df_result = pd.concat([df_result, df_], axis = 0 ) \n    return df_result","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:48:41.441248Z","iopub.execute_input":"2022-10-01T23:48:41.442370Z","iopub.status.idle":"2022-10-01T23:48:41.451372Z","shell.execute_reply.started":"2022-10-01T23:48:41.442320Z","shell.execute_reply":"2022-10-01T23:48:41.450290Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":" ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sum Up: prepare train, test and result file / 主程序","metadata":{}},{"cell_type":"code","source":" def prepare_dfs(use_pd = True, sep = \" \"): \n      \n     columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n          \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n          ,\"sensor20\",\"sensor21\" ] \n\n     # Train\n     df_train = read_data_files( file_name_str = \"train\", use_pd = use_pd, sep = \" \", columns = columns)\n     # Test\n     df_test = read_data_files( file_name_str = \"test\", use_pd = use_pd, sep = \" \", columns = columns)\n\n     resul_columns = [\"rul\"]\n     df_result = read_result(file_name_str = \"RUL_FD\", \\\n          use_pd = use_pd, sep =sep, columns = resul_columns)\n \n     df_train.iloc[:, [0,1]] = df_train.iloc[:, [0,1]].astype(int)\n     df_test.iloc[:, [0,1]] = df_test.iloc[:, [0,1]].astype(int) \n\n     df_max = df_test.groupby([\"Flag\",\"id\"])[\"cycle\"].max().reset_index()\n     df_result = df_result.reset_index()\n     df_result[\"id\"] = df_result.groupby(\"Flag\")[\"index\"].rank(\"first\", ascending = True).astype(int)\n     df_result.drop(columns = [\"index\"], inplace = True)\n     \n     df_result = df_result.merge(df_max, on = [\"Flag\", \"id\"], how = \"inner\")\n      \n     df_result[\"rul_failed\"] = df_result[\"rul\"] + df_result[\"cycle\"]\n\n     df_test = df_test.merge(df_result[[\"rul_failed\", \"Flag\", \"id\"]], on = [\"Flag\", \"id\"], how = \"inner\")\n     df_test[\"remaining_rul\"] = df_test[\"rul_failed\"] - df_test[\"cycle\"]\n\n     #df_test[[\"rul_failed\", \"remaining_rul\"]] = df_test[[\"rul_failed\", \"remaining_rul\"]].astype(int)\n     return df_train, df_test, df_result","metadata":{"execution":{"iopub.status.busy":"2022-10-01T23:49:25.186258Z","iopub.execute_input":"2022-10-01T23:49:25.186735Z","iopub.status.idle":"2022-10-01T23:49:25.202132Z","shell.execute_reply.started":"2022-10-01T23:49:25.186696Z","shell.execute_reply":"2022-10-01T23:49:25.200801Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}